MLOps Assignment ReportHeart Disease Prediction - End-to-End ML PipelineCourse: MLOps (S1-25_AIMLCZG523) 1Assignment: Assignment I - End-to-End ML Model Development, CI/CD, and Production Deployment 2Student: [ACTION REQUIRED: Insert Your Name]ID: [ACTION REQUIRED: Insert Your ID]Date: [ACTION REQUIRED: Insert Date]Table of ContentsExecutive SummaryIntroductionData Acquisition & Exploratory Data AnalysisFeature Engineering & Model DevelopmentExperiment TrackingModel Packaging & ReproducibilityCI/CD Pipeline & Automated TestingModel ContainerizationProduction DeploymentMonitoring & LoggingArchitecture OverviewConclusionExecutive SummaryThis report documents the development and deployment of a scalable machine learning solution for predicting heart disease risk. Per the assignment objectives, the solution implements modern MLOps best practices, including automated data processing, experiment tracking, Continuous Integration/Continuous Deployment (CI/CD), containerization, and cloud-native deployment3.Key Achievements:Automation: Implemented an end-to-end pipeline from data download to model training (src/data/download.py, src/models/train.py).Tracking: Integrated MLflow to log parameters, metrics, and artifacts for Logistic Regression and Random Forest experiments.Reliability: Established a CI/CD pipeline using GitHub Actions to run linting, unit tests, and Docker builds automatically.Deployment: Containerized the FastAPI application using Docker and deployed it using Kubernetes manifests (Deployment, Service, Ingress).Observability: Integrated Prometheus metrics and structured logging for operational monitoring.IntroductionProblem StatementHeart disease is a critical health concern globally. This project aims to build a machine learning classifier to predict the risk of heart disease based on patient health data and deploy this solution as a cloud-ready, monitored API4.DatasetTitle: Heart Disease UCI Dataset5.Source: UCI Machine Learning Repository6.Characteristics: The dataset contains 14+ features including age, sex, blood pressure, and cholesterol, with a binary target indicating the presence or absence of heart disease7.Data Acquisition & Exploratory Data AnalysisData AcquisitionData ingestion is automated via the src/data/download.py script. This script ensures the raw data is downloaded directly from the source, cleaning the workflow and removing manual dependency.[ACTION REQUIRED: Insert Screenshot of python src/data/download.py execution]Exploratory Data Analysis (EDA)A comprehensive EDA was performed in notebooks/eda.ipynb to understand feature distributions and correlations.Key Insights:Target Distribution: Analyzed the class balance between positive and negative heart disease cases.Correlations: Investigated relationships between features (e.g., thalach, oldpeak, cp) and the target variable.Data Integrity: Confirmed handling of missing values and data types via the preprocessing pipeline.[ACTION REQUIRED: Insert 1-2 Screenshots of EDA plots from your notebook, e.g., Correlation Heatmap or Distribution Plot]Feature Engineering & Model DevelopmentFeature EngineeringThe preprocessing pipeline (src/data/preprocessing.py) ensures data is ready for training by performing:Imputation: Handling missing values.Scaling/Encoding: Standardizing numerical features and encoding categorical variables.Reproducibility: The preprocessor is saved alongside the model to ensure inference data undergoes the exact same transformations.Model DevelopmentTwo distinct classification models were trained and evaluated8:Logistic Regression: Selected as a baseline linear model.Random Forest: Selected to capture non-linear relationships.Performance EvaluationModels were evaluated using 5-fold cross-validation. The following metrics were recorded9:ModelAccuracyPrecisionRecallROC-AUCLogistic Regression[Insert Value][Insert Value][Insert Value][Insert Value]Random Forest[Insert Value][Insert Value][Insert Value][Insert Value][ACTION REQUIRED: Insert Screenshot of model training output showing these metrics]Experiment TrackingMLflow was utilized to track all experiments. The training script automatically logs:Parameters: Hyperparameters for both models.Metrics: Accuracy, Precision, Recall, and ROC-AUC.Artifacts: The serialized model files and the preprocessing pipeline.[ACTION REQUIRED: Insert Screenshot of MLflow UI showing the experiment runs list][ACTION REQUIRED: Insert Screenshot of MLflow UI showing specific run details/parameters]Model Packaging & ReproducibilityTo ensure the model is portable and reproducible:Serialization: The final models are saved in Joblib format (models/*.joblib).Dependencies: All libraries are pinned in requirements.txt to prevent version conflicts10.Reproducibility: Random seeds are fixed (set to 42) in the code to ensure consistent training results across runs.Directory Structure:models/
├── best_model.joblib
├── logistic_regression.joblib
├── random_forest.joblib
└── preprocessor.joblib
CI/CD Pipeline & Automated TestingA GitHub Actions workflow (.github/workflows/ci_cd.yml) was created to automate the delivery pipeline11.Pipeline Stages:Linting: Checks code quality using flake8 and black.Testing: Runs unit tests (tests/test_data.py, tests/test_models.py) using pytest to verify data processing and model prediction logic12.Training: Executes the training script to verify model convergence in the CI environment.Containerization: Builds the Docker image if all previous steps pass.[ACTION REQUIRED: Insert Screenshot of GitHub Actions Interface showing a successful pipeline run (all green checks)]Model ContainerizationThe application is wrapped in a Docker container using docker/Dockerfile.Framework: FastAPI is used for the REST API13.Endpoints:POST /predict: Accepts JSON patient data and returns risk prediction14.GET /health: Health check endpoint.Optimization: Multi-stage build is used to minimize image size.Verification:The container was tested locally by mapping port 8000:8000.[ACTION REQUIRED: Insert Screenshot of docker run command or docker images list]Production DeploymentThe solution is deployed using Kubernetes manifests located in the k8s/ directory15.Configuration:Deployment (deployment.yaml): Manages the pods, replicas (set to 3 for scalability), and resource limits.Service (service.yaml): Exposes the application to the network.Ingress (ingress.yaml): Manages external access to the service.[ACTION REQUIRED: Insert Screenshot of kubectl get pods and kubectl get services showing running resources]Monitoring & LoggingLoggingThe API implements structured JSON logging to track request timestamps, input data, and prediction results, facilitating debugging and audit trails16.MetricsPrometheus metrics are exposed at the /metrics endpoint.Key Metrics: Request latency and prediction counts.Integration: These metrics allow for real-time health monitoring of the deployed model.[ACTION REQUIRED: Insert Screenshot of the /metrics endpoint output or API logs]Architecture OverviewThe system follows a modular MLOps architecture:Data Layer: Raw data ingestion from UCI to processed features.Experiment Layer: Model training with MLflow tracking.CI/CD Layer: GitHub Actions for automated testing and image building.Serving Layer: Dockerized FastAPI application running on Kubernetes.Monitoring Layer: Prometheus metrics and application logs.[ACTION REQUIRED: Insert Architecture Diagram (You can draw a simple block diagram based on the description above)]ConclusionThis assignment successfully demonstrated the creation of a production-ready MLOps pipeline. By integrating automated testing, experiment tracking, and container orchestration, the solution addresses the core challenges of reproducibility and scalability in machine learning systems. The deployed API provides reliable heart disease risk predictions suitable for integration into healthcare applications.